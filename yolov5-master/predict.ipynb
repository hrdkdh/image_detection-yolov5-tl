{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no helmet', 'helmet']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_class_info = pd.read_excel(\"../df_class_info.xlsx\")\n",
    "# df_class_info\n",
    "class_info = df_class_info[\"class_name\"].to_list()\n",
    "class_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-3-15 torch 1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 2080 SUPER, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 290 layers, 20856975 parameters, 0 gradients, 48.0 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.torch_utils import select_device\n",
    "\n",
    "device = select_device(0)\n",
    "model_path = \"runs/train/exp13/weights/best.pt\"\n",
    "model = DetectMultiBackend(model_path, device=device)\n",
    "stride, names, pt = model.stride, model.names, model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from utils.augmentations import letterbox\n",
    "from utils.general import non_max_suppression\n",
    "\n",
    "conf_thres=0.25\n",
    "iou_thres=0.45\n",
    "max_det=300\n",
    "\n",
    "def predict(src):\n",
    "    img = letterbox(src, 640, stride=stride, auto=True)[0]\n",
    "    # img = cv2.resize(src, (640, 640), interpolation=cv2.INTER_LINEAR)\n",
    "    dst = img.copy()\n",
    "    img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB Convert\n",
    "    img = np.ascontiguousarray(img)\n",
    "\n",
    "    bs = 1  # batch_size\n",
    "    model.warmup(imgsz=(1 if pt else bs, 3, *(640, 640)))\n",
    "    im = torch.from_numpy(img).to(device)\n",
    "    im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\n",
    "    im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "    if len(im.shape) == 3:\n",
    "        im = im[None]  # expand for batch dim\n",
    "\n",
    "    pred = model(im)\n",
    "    pred = non_max_suppression(pred, conf_thres, iou_thres, None, False, max_det=max_det)\n",
    "    \n",
    "    return dst, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지로 predict\n",
    "factory_img_path = r\"E:\\aihub_safety_dataset\\Training_unziped\\image_factory\"\n",
    "img_list = os.listdir(factory_img_path)\n",
    "colors = [\n",
    "    (0, 50, 200),\n",
    "    (0, 200, 50)\n",
    "]\n",
    "start_no = 3200\n",
    "for idx, imgs in enumerate(img_list[start_no:start_no+5]):\n",
    "    src = cv2.imread(factory_img_path + \"\\\\\" + imgs)\n",
    "    dst, pred = predict(src)\n",
    "    for det in pred[0]:  # per image\n",
    "        # if int(det[-1].item()) == 5:\n",
    "        label = class_info[int(det[5])]\n",
    "        x1 = int((det[0].item()/dst.shape[1]) * src.shape[1])\n",
    "        y1 = int((det[1].item()/dst.shape[0]) * src.shape[0])\n",
    "        x2 = int((det[2].item()/dst.shape[1]) * src.shape[1])\n",
    "        y2 = int((det[3].item()/dst.shape[0]) * src.shape[0])\n",
    "        coords = [x1, y1, x2, y2]\n",
    "\n",
    "        cv2.rectangle(src, (coords[0], coords[1]), (coords[2], coords[3]), colors[int(det[5])], 1)\n",
    "        (text_w, text_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_DUPLEX, 1, 1)\n",
    "        cv2.rectangle(src, (coords[0], coords[1] - text_h), (coords[0] + text_w, coords[1] + text_h-20), colors[int(det[5])], -1)\n",
    "        cv2.putText(src, \"{}\".format(label), (coords[0], coords[1]), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255))\n",
    "\n",
    "    cv2.imshow(\"result\", src)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920.0\n",
      "1080.0\n"
     ]
    }
   ],
   "source": [
    "#카메라로 predict\n",
    "test_video_folder = r\"C:\\Users\\poscohrd\\Desktop\\yolo_transfer_learning\\test_video\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# cv2.namedWindow(\"result\", cv2.WINDOW_NORMAL)\n",
    "colors = [\n",
    "    (0, 50, 200),\n",
    "    (0, 200, 50)\n",
    "]\n",
    "class0_conf_thres = 0.8\n",
    "area_thres = 0.2\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920.0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080.0)\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # 카메라 가로 픽셀 크기 \n",
    "h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # 카메라 세로 픽셀 크기\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)  # 초당 프레임 수\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(test_video_folder + \"/camera_result.mp4\", fourcc, fps, (w, h))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret is False:\n",
    "        break\n",
    "\n",
    "    iou_deviation_thres = frame.shape[0] * 0.05\n",
    "\n",
    "    # print(frame.shape, end=\"\\r\")\n",
    "    dst, pred = predict(frame)\n",
    "\n",
    "    result_list = []\n",
    "    for det in pred[0]:\n",
    "        result_list.append({\n",
    "            \"class_no\" : int(det[5]),\n",
    "            \"label_str\" : \"{} : {:.2f}\".format(class_info[int(det[5])], det[4]),\n",
    "            \"x1\" : int((det[0].item()/dst.shape[1]) * frame.shape[1]),\n",
    "            \"y1\" : int((det[1].item()/dst.shape[0]) * frame.shape[0]),\n",
    "            \"x2\" : int((det[2].item()/dst.shape[1]) * frame.shape[1]),\n",
    "            \"y2\" : int((det[3].item()/dst.shape[0]) * frame.shape[0]),\n",
    "            \"conf\" : det[4].item()\n",
    "        })\n",
    "\n",
    "    for bbox in result_list:  # per image\n",
    "        coords = [bbox[\"x1\"], bbox[\"y1\"], bbox[\"x2\"], bbox[\"y2\"]]\n",
    "\n",
    "        #no helmet의 confidence가 낮으면 컷\n",
    "        if bbox[\"class_no\"] == 0 and bbox[\"conf\"] < class0_conf_thres:\n",
    "            continue\n",
    "        \n",
    "        #겹침 체크해서 겹치면 컷\n",
    "        iou_check = False\n",
    "        if bbox[\"class_no\"] == 0: #no helmet일 경우 helmet과 겹치는 bbox인지 체크\n",
    "            for class1_bbox in [x for x in result_list if x[\"class_no\"] == 1]:\n",
    "                if abs(bbox[\"x1\"] - class1_bbox[\"x1\"]) < iou_deviation_thres and abs(bbox[\"y1\"] - class1_bbox[\"y1\"]) < iou_deviation_thres:\n",
    "                    iou_check = True\n",
    "                    break\n",
    "        \n",
    "        if iou_check is True:\n",
    "            continue\n",
    "\n",
    "        #bbox 면적이 영상크기 대비 일정 % 이상이면 컷\n",
    "        area = (bbox[\"x2\"] - bbox[\"x1\"]) * (bbox[\"y2\"] - bbox[\"y1\"])\n",
    "        ratio = area / (frame.shape[0] * frame.shape[1])\n",
    "        if ratio > area_thres:\n",
    "            cv2.putText(frame, \"too close\", (30, 30), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0))\n",
    "            continue\n",
    "\n",
    "        cv2.rectangle(frame, (coords[0], coords[1]), (coords[2], coords[3]), colors[bbox[\"class_no\"]], 4)\n",
    "\n",
    "        (text_w, text_h), _ = cv2.getTextSize(bbox[\"label_str\"], cv2.FONT_HERSHEY_DUPLEX, 1, 1)\n",
    "        cv2.rectangle(frame, (coords[0], coords[1]), (coords[0] + text_w, coords[1] + text_h + 4), colors[bbox[\"class_no\"]], -1)\n",
    "        cv2.putText(frame, \"{}\".format(bbox[\"label_str\"]), (coords[0], coords[1]+text_h), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255))\n",
    "    \n",
    "    cv2.imshow(\"result\", frame)\n",
    "    out.write(frame)\n",
    "    # cv2.resizeWindow(\"result\", 800, 600)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#동영상으로 predict\n",
    "test_video_folder = r\"C:\\Users\\poscohrd\\Desktop\\yolo_transfer_learning\\test_video\"\n",
    "video_file_list = os.listdir(test_video_folder)\n",
    "colors = [\n",
    "    (0, 50, 200),\n",
    "    (0, 200, 50)\n",
    "]\n",
    "\n",
    "for video in video_file_list[:7]:\n",
    "    cap = cv2.VideoCapture(test_video_folder + \"/\" + video)\n",
    "    class0_conf_thres = 0.8\n",
    "    area_thres = 0.3\n",
    "\n",
    "    w = round(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # 카메라 가로 픽셀 크기 \n",
    "    h = round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # 카메라 세로 픽셀 크기\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # 초당 프레임 수\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(test_video_folder + \"/\" + video.split(\".\")[0] + \"_result.mp4\", fourcc, fps, (w, h))\n",
    "\n",
    "    frame_cnt = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "       \n",
    "        if ret is False:\n",
    "            break\n",
    "\n",
    "        iou_deviation_thres = frame.shape[0] * 0.05\n",
    "        dst, pred = predict(frame)\n",
    "        result_list = []\n",
    "        for det in pred[0]:\n",
    "            result_list.append({\n",
    "                \"class_no\" : int(det[5]),\n",
    "                \"label_str\" : \"{} : {:.2f}\".format(class_info[int(det[5])], det[4]),\n",
    "                \"x1\" : int((det[0].item()/dst.shape[1]) * frame.shape[1]),\n",
    "                \"y1\" : int((det[1].item()/dst.shape[0]) * frame.shape[0]),\n",
    "                \"x2\" : int((det[2].item()/dst.shape[1]) * frame.shape[1]),\n",
    "                \"y2\" : int((det[3].item()/dst.shape[0]) * frame.shape[0]),\n",
    "                \"conf\" : det[4].item()\n",
    "            })\n",
    "\n",
    "        for bbox in result_list:  # per image\n",
    "            coords = [bbox[\"x1\"], bbox[\"y1\"], bbox[\"x2\"], bbox[\"y2\"]]\n",
    "            \n",
    "            #no helmet의 confidence가 낮으면 컷\n",
    "            if bbox[\"class_no\"] == 0 and bbox[\"conf\"] < class0_conf_thres:\n",
    "                continue\n",
    "            \n",
    "            #겹침 체크해서 겹치면 컷\n",
    "            iou_check = False\n",
    "            if bbox[\"class_no\"] == 0: #no helmet일 경우 helmet과 겹치는 bbox인지 체크\n",
    "                for class1_bbox in [x for x in result_list if x[\"class_no\"] == 1]:\n",
    "                    if abs(bbox[\"x1\"] - class1_bbox[\"x1\"]) < iou_deviation_thres and abs(bbox[\"y1\"] - class1_bbox[\"y1\"]) < iou_deviation_thres:\n",
    "                        iou_check = True\n",
    "                        break\n",
    "            \n",
    "            if iou_check is True:\n",
    "                continue\n",
    "\n",
    "            #bbox 면적이 영상크기 대비 30% 이상이면 컷\n",
    "            area = (bbox[\"x2\"] - bbox[\"x1\"]) * (bbox[\"y2\"] - bbox[\"y1\"])\n",
    "            ratio = area / (frame.shape[0] * frame.shape[1])\n",
    "            if ratio > area_thres:\n",
    "                cv2.putText(frame, \"too close\", (30, 30), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 0, 0))\n",
    "                continue\n",
    "\n",
    "            cv2.rectangle(frame, (coords[0], coords[1]-20), (coords[2], coords[3]-20), colors[bbox[\"class_no\"]], 2)\n",
    "\n",
    "            (text_w, text_h), _ = cv2.getTextSize(bbox[\"label_str\"], cv2.FONT_HERSHEY_DUPLEX, 1, 1)\n",
    "            cv2.rectangle(frame, (coords[0], coords[1]-20), (coords[0] + text_w, coords[1] + text_h + 4-20), colors[bbox[\"class_no\"]], -1)\n",
    "            cv2.putText(frame, \"{}\".format(bbox[\"label_str\"]), (coords[0], coords[1]+text_h-20), cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255))\n",
    "\n",
    "        cv2.imshow(\"result\", frame)\n",
    "        out.write(frame)\n",
    "        # cv2.resizeWindow(\"result\", 800, 600)\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "    out.release()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c6dbb939c98599c2f8a89d69240c80e607e568cc462a5cd41a10d11b1549f47"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
